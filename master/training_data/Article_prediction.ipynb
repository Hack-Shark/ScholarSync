{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Article Predictions "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### We made a article recommendation system to predict the articles based on user intrests which is given in the form of prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        },
        "id": "il3k3YyAUKPt",
        "outputId": "e7d0516e-5e00-4655-8d37-197a55739d33"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\vukya\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
            "c:\\Users\\vukya\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
            "c:\\Users\\vukya\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas64__v0.3.21-gcc_10_3_0.dll\n",
            "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Item Title</th>\n",
              "      <th>Publication Title</th>\n",
              "      <th>Authors</th>\n",
              "      <th>Publication Year</th>\n",
              "      <th>URL</th>\n",
              "      <th>Keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Correction to: Strong field physics pursued wi...</td>\n",
              "      <td>AAPPS Bulletin</td>\n",
              "      <td>Vishwa Bandhu PathakSeong Ku LeeKi Hong PaeCal...</td>\n",
              "      <td>2021</td>\n",
              "      <td>http://link.springer.com/article/10.1007/s4367...</td>\n",
              "      <td>AAPPS Bulletin Atomic Molecular Optical and Pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Correction: Time reversal and reciprocity</td>\n",
              "      <td>AAPPS Bulletin</td>\n",
              "      <td>Olivier SigwarthChristian Miniatura</td>\n",
              "      <td>2022</td>\n",
              "      <td>http://link.springer.com/article/10.1007/s4367...</td>\n",
              "      <td>AAPPS Bulletin Atomic Molecular Optical and Pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ultrasound detection using a thermal-assisted ...</td>\n",
              "      <td>AAPPS Bulletin</td>\n",
              "      <td>Jia-Wei MengPei-Ji ZhangShui-Jing TangYun-Feng...</td>\n",
              "      <td>2022</td>\n",
              "      <td>http://link.springer.com/article/10.1007/s4367...</td>\n",
              "      <td>AAPPS Bulletin Atomic Molecular Optical and Pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Relativistic density functional theory in nucl...</td>\n",
              "      <td>AAPPS Bulletin</td>\n",
              "      <td>Jie MengPengwei Zhao</td>\n",
              "      <td>2021</td>\n",
              "      <td>http://link.springer.com/article/10.1007/s4367...</td>\n",
              "      <td>AAPPS Bulletin Atomic Molecular Optical and Pl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Muon cooling and acceleration</td>\n",
              "      <td>AAPPS Bulletin</td>\n",
              "      <td>Masashi Otani</td>\n",
              "      <td>2022</td>\n",
              "      <td>http://link.springer.com/article/10.1007/s4367...</td>\n",
              "      <td>AAPPS Bulletin Atomic Molecular Optical and Pl...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          Item Title Publication Title  \\\n",
              "0  Correction to: Strong field physics pursued wi...    AAPPS Bulletin   \n",
              "1          Correction: Time reversal and reciprocity    AAPPS Bulletin   \n",
              "2  Ultrasound detection using a thermal-assisted ...    AAPPS Bulletin   \n",
              "3  Relativistic density functional theory in nucl...    AAPPS Bulletin   \n",
              "4                      Muon cooling and acceleration    AAPPS Bulletin   \n",
              "\n",
              "                                             Authors  Publication Year  \\\n",
              "0  Vishwa Bandhu PathakSeong Ku LeeKi Hong PaeCal...              2021   \n",
              "1                Olivier SigwarthChristian Miniatura              2022   \n",
              "2  Jia-Wei MengPei-Ji ZhangShui-Jing TangYun-Feng...              2022   \n",
              "3                               Jie MengPengwei Zhao              2021   \n",
              "4                                      Masashi Otani              2022   \n",
              "\n",
              "                                                 URL  \\\n",
              "0  http://link.springer.com/article/10.1007/s4367...   \n",
              "1  http://link.springer.com/article/10.1007/s4367...   \n",
              "2  http://link.springer.com/article/10.1007/s4367...   \n",
              "3  http://link.springer.com/article/10.1007/s4367...   \n",
              "4  http://link.springer.com/article/10.1007/s4367...   \n",
              "\n",
              "                                            Keywords  \n",
              "0  AAPPS Bulletin Atomic Molecular Optical and Pl...  \n",
              "1  AAPPS Bulletin Atomic Molecular Optical and Pl...  \n",
              "2  AAPPS Bulletin Atomic Molecular Optical and Pl...  \n",
              "3  AAPPS Bulletin Atomic Molecular Optical and Pl...  \n",
              "4  AAPPS Bulletin Atomic Molecular Optical and Pl...  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "main=pd.read_csv('springer_data.csv')\n",
        "main=main[main['Language']=='en']\n",
        "main=main.drop(['Language','Item DOI'],axis=1)\n",
        "main.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Z3Fl-nftdxdj"
      },
      "source": [
        "### Journal Dataframe"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Journal articles, keywords, authors concating them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rAqy-9tSd1LQ",
        "outputId": "715359b6-fcc8-4c48-ca43-4837c57ddb94"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Publication Title</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>Articles</th>\n",
              "      <th>Authors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAPPS Bulletin</td>\n",
              "      <td>AAPPS Bulletin Atomic Molecular Optical and Pl...</td>\n",
              "      <td>[Correction to: Strong field physics pursued w...</td>\n",
              "      <td>[Vishwa Bandhu PathakSeong Ku LeeKi Hong PaeCa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAPS PharmSciTech</td>\n",
              "      <td>AAPS PharmSciTech PharmacologyToxicology Biote...</td>\n",
              "      <td>[Correction: Environmental Monitoring for Clos...</td>\n",
              "      <td>[Joseph McCallNonita BarnardKevin GadientChand...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AI &amp; SOCIETY</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Correction to: Dismantling the Chinese Room w...</td>\n",
              "      <td>[Lawrence Lengbeyer, Clare L. E. Foster, Franc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AI and Ethics</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[Publisher Correction: Convergence of the sour...</td>\n",
              "      <td>[Haleh Asgarinia, Jakob MökanderLuciano Florid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AI in Civil Engineering</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[AI in Civil Engineering, Fusion of thermal an...</td>\n",
              "      <td>[Xianzhong Zhao, Quincy G. AlexanderVedhus Hos...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Publication Title                                           Keywords  \\\n",
              "0           AAPPS Bulletin  AAPPS Bulletin Atomic Molecular Optical and Pl...   \n",
              "1        AAPS PharmSciTech  AAPS PharmSciTech PharmacologyToxicology Biote...   \n",
              "2             AI & SOCIETY                                                NaN   \n",
              "3            AI and Ethics                                                NaN   \n",
              "4  AI in Civil Engineering                                                NaN   \n",
              "\n",
              "                                            Articles  \\\n",
              "0  [Correction to: Strong field physics pursued w...   \n",
              "1  [Correction: Environmental Monitoring for Clos...   \n",
              "2  [Correction to: Dismantling the Chinese Room w...   \n",
              "3  [Publisher Correction: Convergence of the sour...   \n",
              "4  [AI in Civil Engineering, Fusion of thermal an...   \n",
              "\n",
              "                                             Authors  \n",
              "0  [Vishwa Bandhu PathakSeong Ku LeeKi Hong PaeCa...  \n",
              "1  [Joseph McCallNonita BarnardKevin GadientChand...  \n",
              "2  [Lawrence Lengbeyer, Clare L. E. Foster, Franc...  \n",
              "3  [Haleh Asgarinia, Jakob MökanderLuciano Florid...  \n",
              "4  [Xianzhong Zhao, Quincy G. AlexanderVedhus Hos...  "
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "journal_art = main.groupby('Publication Title')['Item Title'].apply(list).reset_index(name='Articles')\n",
        "journal_art.set_index(['Publication Title'],inplace=True)\n",
        "journal_auth = main.groupby('Publication Title')['Authors'].apply(list).reset_index(name='Authors')\n",
        "journal_auth.set_index(['Publication Title'],inplace=True)\n",
        "journal_key= main.drop_duplicates(subset=[\"Publication Title\", \"Keywords\"], keep='first')\n",
        "journal_key=journal_key.drop(['Item Title','Authors','Publication Year','URL'],axis=1)\n",
        "journal_key.set_index(['Publication Title'],inplace=True)\n",
        "journal_main = pd.concat([journal_key, journal_art,journal_auth], axis=1, join='inner')\n",
        "journal_main=journal_main.reset_index()\n",
        "journal_main.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Changing into paragraphs from lists"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### get paragraph:\n",
        "1. combines joins the list of the data into a paragraph\n",
        "##### get cleaned_text:\n",
        "1. check if the instance is string\n",
        "2. re.match(r'^[a-zA-Z]+$', word) checks if the word consists only of alphabetic characters\n",
        "3. word not in stop_words checks if the word is not in a list of stop words.\n",
        "4. len(word) > 1 checks if the word has a length greater than 1.\n",
        "5. word[1] != '.' checks if the second character of the word is not a dot (.) character.\n",
        "##### combine text:\n",
        "1. combines all the indices required in the list of indices into a paragraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\vukya\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\vukya\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\vukya\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def get_paragraph(row,index):\n",
        "  ans=''\n",
        "  for x in row[index]:\n",
        "    ans=ans+'  '+x.lower()\n",
        "  return ans\n",
        "def get_clean_text(row,index):\n",
        "    if not isinstance(row[index], str):\n",
        "        return '' \n",
        "    clean_text=''\n",
        "    words = re.findall(r'\\b\\w+\\b', row[index].lower())\n",
        "    words = row[index].lower().split()\n",
        "    for word in words:\n",
        "        if( re.match(r'^[a-zA-Z]+$', word) and  word not in stop_words and len(word) >1 and word[1] != '.'):\n",
        "            clean_text=clean_text+' '+word\n",
        "    return clean_text\n",
        "def combine(row,indices):\n",
        "    ans=''\n",
        "    for i in indices:\n",
        "      ans=ans+' '+row[i]\n",
        "    return ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Publication Title</th>\n",
              "      <th>Keywords</th>\n",
              "      <th>Articles</th>\n",
              "      <th>Authors</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAPPS Bulletin</td>\n",
              "      <td>aapps bulletin atomic molecular optical plasm...</td>\n",
              "      <td>correction strong field physics pursued petaw...</td>\n",
              "      <td>vishwa bandhu pathakseong ku leeki hong paeca...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAPS PharmSciTech</td>\n",
              "      <td>aaps pharmscitech pharmacologytoxicology biot...</td>\n",
              "      <td>environmental monitoring closed robotic workc...</td>\n",
              "      <td>joseph mccallnonita barnardkevin gadientchand...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AI &amp; SOCIETY</td>\n",
              "      <td></td>\n",
              "      <td>correction dismantling chinese room linguisti...</td>\n",
              "      <td>lawrence lengbeyer clare foster francesca fof...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AI and Ethics</td>\n",
              "      <td></td>\n",
              "      <td>publisher convergence source control actual a...</td>\n",
              "      <td>haleh asgarinia jakob floridi robert hannaemr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AI in Civil Engineering</td>\n",
              "      <td></td>\n",
              "      <td>ai civil engineering fusion thermal rgb image...</td>\n",
              "      <td>xianzhong zhao quincy alexandervedhus hoskere...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Publication Title                                           Keywords  \\\n",
              "0           AAPPS Bulletin   aapps bulletin atomic molecular optical plasm...   \n",
              "1        AAPS PharmSciTech   aaps pharmscitech pharmacologytoxicology biot...   \n",
              "2             AI & SOCIETY                                                      \n",
              "3            AI and Ethics                                                      \n",
              "4  AI in Civil Engineering                                                      \n",
              "\n",
              "                                            Articles  \\\n",
              "0   correction strong field physics pursued petaw...   \n",
              "1   environmental monitoring closed robotic workc...   \n",
              "2   correction dismantling chinese room linguisti...   \n",
              "3   publisher convergence source control actual a...   \n",
              "4   ai civil engineering fusion thermal rgb image...   \n",
              "\n",
              "                                             Authors  \n",
              "0   vishwa bandhu pathakseong ku leeki hong paeca...  \n",
              "1   joseph mccallnonita barnardkevin gadientchand...  \n",
              "2   lawrence lengbeyer clare foster francesca fof...  \n",
              "3   haleh asgarinia jakob floridi robert hannaemr...  \n",
              "4   xianzhong zhao quincy alexandervedhus hoskere...  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "journal_main['Articles']=journal_main.apply(get_paragraph,index='Articles',axis=1)\n",
        "journal_main['Articles']=journal_main.apply(get_clean_text,index='Articles',axis=1)\n",
        "journal_main['Authors']=journal_main.apply(get_paragraph,index='Authors',axis=1)\n",
        "journal_main['Authors']=journal_main.apply(get_clean_text,index='Authors',axis=1)\n",
        "journal_main['Keywords']=journal_main.apply(get_clean_text,index=1,axis=1)\n",
        "journal_main.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature Extraction taking nouns and adjectives as features"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Preprocessing the text"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is possible to predict journals using only nouns and adjectives as features. By focusing on nouns and adjectives, we can capture key information and characteristics of the articles that may be relevant for predicting the corresponding journals."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "journal_main['Tokenized'] = journal_main['Articles'].apply(word_tokenize)\n",
        "journal_main['Tagged'] = journal_main['Tokenized'].apply(pos_tag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Publication Title</th>\n",
              "      <th>Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AAPPS Bulletin</td>\n",
              "      <td>aapps bulletin atomic molecular optical plasm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AAPS PharmSciTech</td>\n",
              "      <td>aaps pharmscitech pharmacologytoxicology biot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AI &amp; SOCIETY</td>\n",
              "      <td>correction chinese room linguistic framework ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AI and Ethics</td>\n",
              "      <td>publisher convergence source control actual a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AI in Civil Engineering</td>\n",
              "      <td>civil engineering fusion thermal rgb images d...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Publication Title                                               Tags\n",
              "0           AAPPS Bulletin   aapps bulletin atomic molecular optical plasm...\n",
              "1        AAPS PharmSciTech   aaps pharmscitech pharmacologytoxicology biot...\n",
              "2             AI & SOCIETY   correction chinese room linguistic framework ...\n",
              "3            AI and Ethics   publisher convergence source control actual a...\n",
              "4  AI in Civil Engineering   civil engineering fusion thermal rgb images d..."
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "journal_main['Tags'] = journal_main['Tagged'].apply(lambda x: [word for word, tag in x if tag.startswith('NN') or tag.startswith('JJ')])\n",
        "journal_main['Tags'] = journal_main['Tags'].apply(lambda x: [word for word in x if word.lower() not in stop_words])\n",
        "journal_main['Tags']=journal_main.apply(get_paragraph,index='Tags',axis=1)\n",
        "journal_main=journal_main.drop(['Articles','Tokenized','Tagged'],axis=1)\n",
        "journal_main['Tags']=journal_main.apply(combine,indices=['Keywords','Tags','Authors'],axis=1)\n",
        "journal_main['Tags']=journal_main.apply(get_clean_text,index='Tags',axis=1)\n",
        "journal_main=journal_main.drop(['Keywords','Authors'],axis=1)\n",
        "journal_main.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### TFIDF vector for journal prediction "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZkbEdmV4dsOz"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "vectorizer = TfidfVectorizer(decode_error='ignore',strip_accents='ascii')\n",
        "journal_tfidf_matrix = vectorizer.fit_transform(journal_main['Tags'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "we predict based on cosine similarities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "journal_threshold=4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDF4ynyZftUU",
        "outputId": "43afa80d-eb18-4b69-f311-31e4fb25cadb"
      },
      "outputs": [],
      "source": [
        "def get_journal_index(user_input):\n",
        "    user_tfidf = vectorizer.transform([user_input])\n",
        "    cosine_similarities = cosine_similarity(user_tfidf, journal_tfidf_matrix).flatten()\n",
        "    indices = cosine_similarities.argsort()[::-1]\n",
        "    top_recommendations = [i for i in indices if cosine_similarities[i] > 0][:min(journal_threshold, len(indices))]\n",
        "    return top_recommendations"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Preparing individual article dataframes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mOvtQlE2ion5"
      },
      "outputs": [],
      "source": [
        "def get_article_df(row):\n",
        "    article = main.loc[main['Publication Title'] == journal_main['Publication Title'][row.name]].copy()\n",
        "    article['Item Title']=article.apply(get_clean_text,index='Item Title',axis=1)\n",
        "    article['Authors']=article.apply(get_clean_text,index='Authors',axis=1)\n",
        "    article['Tokenized'] = article['Item Title'].apply(word_tokenize)\n",
        "    article['Tagged'] = article['Tokenized'].apply(pos_tag)\n",
        "    article['Tags'] = article['Tagged'].apply(lambda x: [word for word, tag in x if tag.startswith('NN') or tag.startswith('JJ')and word.lower() not in stop_words])\n",
        "    article['Tags']=article.apply(get_paragraph,index='Tags',axis=1)\n",
        "    article['Tags']=article.apply(lambda x : x['Tags']+' '+x['Authors']+' '+str(x['Publication Year']),axis=1)\n",
        "    article=article.drop(['Keywords','Publication Title','Tokenized','Tagged','Authors','Publication Year'],axis=1)\n",
        "    article.reset_index(inplace=True)\n",
        "    article.set_index('index', inplace=True)\n",
        "    return article\n",
        "\n",
        "journal_main['article_df']=journal_main.apply(get_article_df,axis=1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Generating tfidf matrices for the journals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_vectorizer(row):\n",
        "    vectorizer = TfidfVectorizer(decode_error='ignore',strip_accents='ascii')\n",
        "    return vectorizer\n",
        "def get_tfidf_matrix(row):\n",
        "    tfidf_matrix = row['article_vectorizer'].fit_transform(row['article_df']['Tags'])\n",
        "    return tfidf_matrix\n",
        "journal_main['article_vectorizer']=journal_main.apply(get_vectorizer,axis=1)\n",
        "journal_main['article_matrix']=journal_main.apply(get_tfidf_matrix,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "article_threshold=10"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Article recommendation using user input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_article_recommendations(user_input):\n",
        "    recommended_journals=get_journal_index(user_input)\n",
        "    l=[]\n",
        "    for journal_id in recommended_journals:\n",
        "        user_tfidf=journal_main['article_vectorizer'][journal_id].transform([user_input])\n",
        "        cosine_similarities = cosine_similarity(user_tfidf, journal_main['article_matrix'][journal_id]).flatten()\n",
        "        indices = cosine_similarities.argsort()[::-1]\n",
        "        top_recommendation_articles = [(cosine_similarities[i],i,journal_id) for i in indices if cosine_similarities[i] > 0][:min(article_threshold, len(indices))]\n",
        "        l=l+top_recommendation_articles\n",
        "    l.sort(reverse=True)\n",
        "    return l\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(' language test activism', 'http://link.springer.com/article/10.1007/s10993-022-09614-7'), (' language advocacy times securitization network languagerights', 'http://link.springer.com/article/10.1007/s10993-022-09617-4'), (' attribution autonomy role robotic language acquisition', 'http://link.springer.com/article/10.1007/s00146-020-01114-8'), (' auditing large language approach', 'http://link.springer.com/article/10.1007/s43681-023-00289-2'), (' officiality strategic ambiguity language exploring migrant experiences andorra luxembourg', 'http://link.springer.com/article/10.1007/s10993-021-09602-3'), (' bias comparison framework abusive language datasets', 'http://link.springer.com/article/10.1007/s43681-021-00081-0'), (' ai management beyond exploring ai organizational context', 'http://link.springer.com/article/10.1007/s00146-021-01249-2'), (' automated occupation coding hierarchical approach classification language models', 'http://link.springer.com/article/10.1007/s44163-023-00050-y'), (' natural language processing analysis applied opinions using distilbert model sentiment categorization', 'http://link.springer.com/article/10.1007/s00146-022-01594-w'), (' identity ai', 'http://link.springer.com/article/10.1007/s44163-022-00038-0'), (' evolution language ideological debates english french multilingual humanitarian organisation', 'http://link.springer.com/article/10.1007/s10993-021-09586-0'), (' reflections human role ai policy national ai strategies view', 'http://link.springer.com/article/10.1007/s44163-022-00019-3'), (' analysis news sentiments using natural language processing deep learning', 'http://link.springer.com/article/10.1007/s00146-020-01111-x'), (' ai doctor see assessing framing ai news coverage', 'http://link.springer.com/article/10.1007/s00146-021-01145-9'), (' subnational ai shaping ai governance system', 'http://link.springer.com/article/10.1007/s00146-022-01561-5'), (' explainable ai lacks regulative ai human equally opaque', 'http://link.springer.com/article/10.1007/s43681-022-00217-w'), (' making ai ai futures frames german political media discourses', 'http://link.springer.com/article/10.1007/s00146-021-01161-9'), (' ai social theory', 'http://link.springer.com/article/10.1007/s00146-021-01222-z'), (' ai framework measuring embodied carbon ai systems', 'http://link.springer.com/article/10.1007/s43681-021-00071-2'), (' perceptions attitudes qatar university students regarding utility arabic english communication education qatar', 'http://link.springer.com/article/10.1007/s10993-021-09590-4'), (' identity ai', 'http://link.springer.com/article/10.1007/s44163-023-00054-8'), (' perspectives ai adoption role italian ai strategy', 'http://link.springer.com/article/10.1007/s44163-022-00025-5'), (' tech industry hijacking ai ethics research agenda reclaim', 'http://link.springer.com/article/10.1007/s44163-022-00043-3'), (' uselessness ai ethics', 'http://link.springer.com/article/10.1007/s43681-022-00209-w'), (' openness privacy reflecting role ai development', 'http://link.springer.com/article/10.1007/s00146-021-01361-3'), (' vision lack alignment ai strategies energy regulations dutch electricity sector', 'http://link.springer.com/article/10.1007/s44163-022-00040-6'), (' ai ethics review three recent publications', 'http://link.springer.com/article/10.1007/s00146-020-01087-8'), (' putting ai ethics tools fit', 'http://link.springer.com/article/10.1007/s43681-021-00084-x'), (' beyond implementing ethical ai', 'http://link.springer.com/article/10.1007/s43681-020-00011-6'), (' rawlsian ai fairness loopholes', 'http://link.springer.com/article/10.1007/s43681-022-00226-9'), (' language planning multilingual minoritized language perspective', 'http://link.springer.com/article/10.1007/s10993-015-9397-4'), (' glitters trustworthy ethical ai principles', 'http://link.springer.com/article/10.1007/s43681-022-00232-x'), (' language anishinaabemowin language planning using', 'http://link.springer.com/article/10.1007/s10993-023-09656-5'), (' ai ethics systemic risks finance', 'http://link.springer.com/article/10.1007/s43681-021-00129-1'), (' public sector ai transparency uk government seeks lead example', 'http://link.springer.com/article/10.1007/s44163-022-00018-4'), (' ai impacts supply chain performance manufacturing use case study', 'http://link.springer.com/article/10.1007/s44163-023-00061-9'), (' charting ai conceptual sources spatial implications urban artificial intelligence', 'http://link.springer.com/article/10.1007/s44163-023-00060-w'), (' normative language policy minority language rethinking case regional languages france', 'http://link.springer.com/article/10.1007/s10993-016-9411-5'), (' linguistic still valid construct relation language policy irish sign language', 'http://link.springer.com/article/10.1007/s10993-017-9446-2'), (' new speakers new old investigation gap language practices language policy', 'http://link.springer.com/article/10.1007/s10993-018-9503-5')]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def get_links(user_input):\n",
        "    l=[]\n",
        "    recommendation_list=get_article_recommendations(user_input)\n",
        "    for article in recommendation_list:\n",
        "        cosine_similarity,article_id,journal_id=article\n",
        "        l.append((journal_main['article_df'][journal_id].iloc[article_id,0],journal_main['article_df'][journal_id].iloc[article_id,1]))\n",
        "        # print(name,url)\n",
        "    return l\n",
        "user_input = \"AI is my favourite language in 2022\"\n",
        "l=get_links(user_input)\n",
        "print(l)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
